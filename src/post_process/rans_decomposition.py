import h5py
import numpy as np
import os
import glob
from tqdm import tqdm

# ================= Configuration =================
SOURCE_ROOT = "output"  # åŸå§‹æ¨¡æ“¬è³‡æ–™æ ¹ç›®éŒ„
POSTPROCESS_ROOT = "output_postprocess"  # å¾Œè™•ç†çµæœè¼¸å‡ºç›®éŒ„
DATASET_KEY = "velocity"  # H5 å…§çš„ dataset åç¨± (ä¾‹å¦‚ 'velocity', 'u', 'flow')
# =================================================


def read_h5_data(filepath, key):
    """è®€å– H5 æª”æ¡ˆä¸¦è½‰ç‚º float64"""
    with h5py.File(filepath, "r") as f:
        if key not in f:
            # è‡ªå‹•å˜—è©¦æŠ“å–ç¬¬ä¸€å€‹ key
            keys = list(f.keys())
            if not keys:
                raise ValueError(f"Empty h5 file: {filepath}")
            key = keys[0]
        data = f[key][:]
    return data.astype(np.float64)


def save_h5_data(filepath, data, key_name, attrs=None):
    """å°è£å­˜æª”é‚è¼¯"""
    with h5py.File(filepath, "w") as f:
        dset = f.create_dataset(key_name, data=data, compression="gzip")
        if attrs:
            for k, v in attrs.items():
                f.attrs[k] = v


def process_batch(batch_name):
    """
    è™•ç†å–®ä¸€ Batchï¼š
    1. Pass 1: è¨ˆç®— RANS Mean & Sum Magnitude
    2. Pass 2: è¨ˆç®— Fluctuations (u' = u - u_mean)
    """

    # 1. å®šç¾©è·¯å¾‘
    src_dir = os.path.join(SOURCE_ROOT, batch_name, "h5_SimData")
    dest_dir = os.path.join(POSTPROCESS_ROOT, batch_name)
    fluc_dir = os.path.join(dest_dir, "fluctuations")  # å°ˆé–€æ”¾è„ˆè¡å ´çš„è³‡æ–™å¤¾

    if not os.path.exists(src_dir):
        print(f"[Skip] Source dir not found: {src_dir}")
        return

    # å»ºç«‹è¼¸å‡ºç›®éŒ„
    os.makedirs(dest_dir, exist_ok=True)
    os.makedirs(fluc_dir, exist_ok=True)

    # ç²å–æª”æ¡ˆåˆ—è¡¨
    h5_files = sorted(glob.glob(os.path.join(src_dir, "*.h5")))
    if not h5_files:
        print(f"[Skip] No h5 files in {batch_name}")
        return

    print(f"\nğŸš€ Processing Batch: {batch_name}")
    print(f"   ğŸ“‚ Input: {src_dir}")
    print(f"   ğŸ“‚ Output: {dest_dir}")

    # ==========================================
    # Pass 1: è¨ˆç®—æ™‚é–“å¹³å‡ (Time Averaging)
    # ==========================================
    velocity_sum = None
    mag_sum = None
    count = 0

    print("   ğŸ‘‰ Pass 1: Calculating RANS Mean...")
    for fpath in tqdm(h5_files, unit="frame", ncols=80):
        try:
            # è®€å–
            u_inst = read_h5_data(fpath, DATASET_KEY)

            # è¨ˆç®— Magnitude (å‡è¨­æœ€å¾Œä¸€ç¶­æ˜¯ u,v åˆ†é‡)
            # è‹¥ shape ç‚º (H, W, 2) -> axis=-1; è‹¥ (2, H, W) -> axis=0
            axis_dim = -1 if u_inst.shape[-1] == 2 else 0
            u_mag = np.linalg.norm(u_inst, axis=axis_dim)

            # åˆå§‹åŒ– Accumulator
            if velocity_sum is None:
                velocity_sum = np.zeros_like(u_inst)
                mag_sum = np.zeros_like(u_mag)

            # ç´¯åŠ 
            velocity_sum += u_inst
            mag_sum += u_mag
            count += 1

        except Exception as e:
            print(f"      [Warn] Error reading {os.path.basename(fpath)}: {e}")

    if count == 0:
        print("      [Error] No valid frames found.")
        return

    # è¨ˆç®—å¹³å‡å€¼
    u_mean = velocity_sum / count
    mag_sum_final = mag_sum  # æ ¹æ“šéœ€æ±‚ï¼Œé€™æ˜¯ sum ä¸æ˜¯ mean

    # å­˜æª” RANS & Sum Mag
    save_h5_data(
        os.path.join(dest_dir, "rans.h5"),
        u_mean,
        "mean_velocity",
        {"description": "Time-Averaged Velocity Field (RANS)", "frames": count},
    )

    save_h5_data(
        os.path.join(dest_dir, "sum_mag.h5"),
        mag_sum_final,
        "sum_magnitude",
        {"description": "Accumulated Velocity Magnitude", "frames": count},
    )

    print(f"      âœ… Saved rans.h5 & sum_mag.h5")

    # ==========================================
    # Pass 2: è¨ˆç®—æ¹æµè„ˆè¡ (Fluctuations)
    # u' = u_raw - u_mean
    # ==========================================
    print("   ğŸ‘‰ Pass 2: Calculating Fluctuations (u' = u - u_mean)...")

    # ç‚ºäº†ç¯€çœè¨˜æ†¶é«”ï¼Œæˆ‘å€‘å¿…é ˆå†è®€ä¸€æ¬¡æª”æ¡ˆï¼Œè€Œä¸æ˜¯æŠŠæ‰€æœ‰ frames å­˜åœ¨ RAM
    for fpath in tqdm(h5_files, unit="frame", ncols=80):
        try:
            # è®€å–åŸå§‹ç¬æ™‚å ´
            u_inst = read_h5_data(fpath, DATASET_KEY)

            # è¨ˆç®—è„ˆè¡ (Broadcasting: (H,W,2) - (H,W,2))
            u_prime = u_inst - u_mean

            # æ§‹å»ºè¼¸å‡ºæª”å (ä¿æŒåŸå§‹æª”åï¼ŒåŠ ä¸Š prefix æˆ–æ”¾åœ¨è³‡æ–™å¤¾å…§)
            fname = os.path.basename(fpath)
            out_name = f"fluc_{fname}"
            out_path = os.path.join(fluc_dir, out_name)

            # å­˜æª”
            save_h5_data(
                out_path,
                u_prime,
                "fluctuation",
                {"description": "Instantaneous Turbulent Fluctuation (u - u_mean)"},
            )

        except Exception as e:
            print(f"      [Warn] Error processing fluctuation for {fname}: {e}")

    print(f"      âœ… Saved {count} fluctuation fields to /fluctuations/")


# ==========================================
# Main Execution
# ==========================================
if __name__ == "__main__":
    if not os.path.exists(SOURCE_ROOT):
        print(f"Error: Source directory '{SOURCE_ROOT}' does not exist.")
        exit()

    # æƒæ output/ ä¸‹çš„æ‰€æœ‰è³‡æ–™å¤¾
    subdirs = [
        d
        for d in os.listdir(SOURCE_ROOT)
        if os.path.isdir(os.path.join(SOURCE_ROOT, d))
    ]

    print(f"--- LBM Post-Processing: RANS & Fluctuations ---")
    print(f"Total Batches Found: {len(subdirs)}\n")

    for batch in subdirs:
        process_batch(batch)

    print("\n--- All tasks completed ---")
